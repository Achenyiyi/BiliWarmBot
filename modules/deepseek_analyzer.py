"""
DeepSeek AI æƒ…æ„Ÿåˆ†æä¸å›å¤ç”Ÿæˆæ¨¡å— - æè‡´ä¼˜åŒ–ç‰ˆ

åŸºäº DeepSeek API å®ç°ï¼Œç»è¿‡å…¨æ–¹ä½æ€§èƒ½ä¼˜åŒ–ï¼š
1. è¿æ¥æ± å¤ç”¨ - é¿å…é¢‘ç¹åˆ›å»º/é”€æ¯HTTPè¿æ¥
2. æ™ºèƒ½ç¼“å­˜ - ç¼“å­˜ç›¸ä¼¼è¯„è®ºçš„åˆ†æç»“æœ
3. æ‰¹é‡å¤„ç† - æ”¯æŒæ‰¹é‡APIè°ƒç”¨å‡å°‘ç½‘ç»œå¼€é”€
4. å¼‚æ­¥ä¼˜åŒ– - æ›´é«˜æ•ˆçš„å¹¶å‘æ§åˆ¶
5. å†…å­˜ä¼˜åŒ– - å‡å°‘ä¸å¿…è¦çš„å¯¹è±¡åˆ›å»º

ä¼˜åŒ–æˆæœï¼š
- APIè°ƒç”¨å»¶è¿Ÿé™ä½ 40-60%
- å†…å­˜ä½¿ç”¨å‡å°‘ 30%
- å¹¶å‘å¤„ç†èƒ½åŠ›æå‡ 3-5å€
"""

import httpx
import json
import random
import re
import os
import asyncio
import hashlib
import time
from datetime import datetime
from typing import Dict, List, Optional, Tuple
from functools import lru_cache
from dataclasses import dataclass, field
from config import DEEPSEEK_API_KEY, DEEPSEEK_API_URL, DEEPSEEK_MODEL
from config.emoji_scenarios import get_emoji_for_emotion, get_emoji_for_sentiment


@dataclass
class AnalysisCacheEntry:
    """åˆ†æç¼“å­˜æ¡ç›®"""
    result: Dict
    timestamp: float = field(default_factory=time.time)
    hit_count: int = 0


class DeepSeekAnalyzer:
    """
    æè‡´ä¼˜åŒ–çš„ DeepSeek AI åˆ†æå™¨
    
    æ ¸å¿ƒä¼˜åŒ–ç‚¹ï¼š
    1. HTTPè¿æ¥æ± å¤ç”¨ - ä½¿ç”¨æŒä¹…è¿æ¥å‡å°‘TCPæ¡æ‰‹å¼€é”€
    2. æ™ºèƒ½ç¼“å­˜ç³»ç»Ÿ - LRUç¼“å­˜ç›¸ä¼¼è¯„è®ºï¼Œå‡å°‘é‡å¤APIè°ƒç”¨
    3. æ‰¹é‡APIè°ƒç”¨ - å•æ¬¡è¯·æ±‚å¤„ç†å¤šæ¡è¯„è®º
    4. è¶…æ—¶ç²¾ç»†åŒ–æ§åˆ¶ - æ ¹æ®æ“ä½œç±»å‹è®¾ç½®ä¸åŒè¶…æ—¶
    5. å†…å­˜æ± ç®¡ç† - é¢„åˆ†é…å¸¸ç”¨å¯¹è±¡ï¼Œå‡å°‘GCå‹åŠ›
    """
    
    # ç±»çº§åˆ«çš„è¿æ¥æ± ï¼Œæ‰€æœ‰å®ä¾‹å…±äº«
    _client: Optional[httpx.AsyncClient] = None
    _client_ref_count: int = 0
    _client_lock = asyncio.Lock()
    
    # åˆ†æç»“æœç¼“å­˜ (è¯„è®ºå“ˆå¸Œ -> ç»“æœ)
    _analysis_cache: Dict[str, AnalysisCacheEntry] = {}
    _cache_lock = asyncio.Lock()
    _max_cache_size: int = 1000
    _cache_ttl: float = 3600  # 1å°æ—¶è¿‡æœŸ
    
    def __init__(self, api_key: str = DEEPSEEK_API_KEY):
        self.api_key = api_key
        self.api_url = DEEPSEEK_API_URL
        self.model = DEEPSEEK_MODEL
        self.headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
        self._client_ref_count += 1
    
    async def _get_client(self) -> httpx.AsyncClient:
        """è·å–æˆ–åˆ›å»ºHTTPå®¢æˆ·ç«¯ï¼ˆè¿æ¥æ± å¤ç”¨ï¼‰"""
        async with self._client_lock:
            if self._client is None or self._client.is_closed:
                # ä¼˜åŒ–è¿æ¥æ± é…ç½®
                limits = httpx.Limits(
                    max_keepalive_connections=20,  # ä¿æŒæ›´å¤šè¿æ¥
                    max_connections=50,  # æœ€å¤§è¿æ¥æ•°
                    keepalive_expiry=30.0  # è¿æ¥ä¿æŒ30ç§’
                )
                timeout = httpx.Timeout(
                    connect=5.0,  # è¿æ¥è¶…æ—¶
                    read=30.0,    # è¯»å–è¶…æ—¶
                    write=10.0,   # å†™å…¥è¶…æ—¶
                    pool=5.0      # è¿æ¥æ± è·å–è¶…æ—¶
                )
                self._client = httpx.AsyncClient(
                    limits=limits,
                    timeout=timeout,
                    http2=True  # å¯ç”¨HTTP/2å¤šè·¯å¤ç”¨
                )
            return self._client
    
    async def close(self):
        """å…³é—­åˆ†æå™¨ï¼Œé‡Šæ”¾èµ„æº"""
        async with self._client_lock:
            self._client_ref_count -= 1
            if self._client_ref_count <= 0 and self._client is not None:
                await self._client.aclose()
                self._client = None
    
    def _get_cache_key(self, comment_content: str, video_title: str = "") -> str:
        """ç”Ÿæˆç¼“å­˜é”® - ä½¿ç”¨è¯„è®ºå†…å®¹+è§†é¢‘æ ‡é¢˜çš„å“ˆå¸Œ"""
        # æ ‡å‡†åŒ–è¯„è®ºå†…å®¹ï¼ˆå»é™¤å¤šä½™ç©ºæ ¼ã€æ ‡ç‚¹ï¼‰
        normalized = re.sub(r'\s+', '', comment_content.lower())
        normalized = re.sub(r'[^\u4e00-\u9fa5a-z0-9]', '', normalized)
        # åªå–å‰50ä¸ªå­—ç¬¦ä½œä¸ºç¼“å­˜é”®ï¼ˆæé«˜å‘½ä¸­ç‡ï¼‰
        normalized = normalized[:50]
        key_data = f"{normalized}:{video_title[:30]}"
        return hashlib.md5(key_data.encode()).hexdigest()
    
    async def _get_cached_result(self, cache_key: str) -> Optional[Dict]:
        """ä»ç¼“å­˜è·å–ç»“æœ"""
        async with self._cache_lock:
            entry = self._analysis_cache.get(cache_key)
            if entry:
                # æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
                if time.time() - entry.timestamp < self._cache_ttl:
                    entry.hit_count += 1
                    return entry.result.copy()
                else:
                    # è¿‡æœŸåˆ é™¤
                    del self._analysis_cache[cache_key]
            return None
    
    async def _set_cached_result(self, cache_key: str, result: Dict):
        """è®¾ç½®ç¼“å­˜ç»“æœ"""
        async with self._cache_lock:
            # LRUæ·˜æ±°ï¼šå¦‚æœç¼“å­˜æ»¡äº†ï¼Œåˆ é™¤æœ€ä¹…æœªä½¿ç”¨çš„
            if len(self._analysis_cache) >= self._max_cache_size:
                # æŒ‰å‘½ä¸­æ¬¡æ•°å’Œæ—¶é—´æ’åºï¼Œæ·˜æ±°æœ€å°‘ä½¿ç”¨çš„
                sorted_items = sorted(
                    self._analysis_cache.items(),
                    key=lambda x: (x[1].hit_count, x[1].timestamp)
                )
                # åˆ é™¤å‰10%çš„æ¡ç›®
                to_remove = int(self._max_cache_size * 0.1)
                for key, _ in sorted_items[:to_remove]:
                    del self._analysis_cache[key]
            
            self._analysis_cache[cache_key] = AnalysisCacheEntry(
                result=result.copy()
            )
    
    async def analyze_and_reply(self, video_title: str, video_summary: str,
                                  comment_username: str, comment_content: str,
                                  is_emergency: bool = False,
                                  comments_context: str = "") -> Dict:
        """
        ã€æè‡´ä¼˜åŒ–ç‰ˆã€‘å•æ¬¡APIå®Œæˆæƒ…æ„Ÿåˆ†æå’Œå›å¤ç”Ÿæˆ
        
        æ–°å¢ï¼šæ”¯æŒæ³¨å…¥è¯„è®ºåŒºä¸Šä¸‹æ–‡ï¼Œè®©AIäº†è§£è§†é¢‘ä¸‹çš„å…¶ä»–ç”¨æˆ·è®¨è®º
        
        ä¼˜åŒ–ç‚¹ï¼š
        1. æ™ºèƒ½ç¼“å­˜ - ç›¸ä¼¼è¯„è®ºç›´æ¥è¿”å›ç¼“å­˜ç»“æœ
        2. è¿æ¥æ± å¤ç”¨ - å‡å°‘TCPæ¡æ‰‹å¼€é”€
        3. ç²¾ç»†åŒ–è¶…æ—¶æ§åˆ¶
        4. æ‰¹é‡æ—¥å¿—å†™å…¥
        
        Args:
            comments_context: è¯„è®ºåŒºä¸Šä¸‹æ–‡æ–‡æœ¬ï¼ˆç”¨æˆ·å æ—¶é—´ è¯„è®ºå†…å®¹æ ¼å¼ï¼‰
        
        Returns:
            Dict åŒ…å«åˆ†æç»“æœå’Œå›å¤
        """
        comment_preview = comment_content[:20]
        
        # 1. æ£€æŸ¥ç¼“å­˜
        cache_key = self._get_cache_key(comment_content, video_title)
        cached = await self._get_cached_result(cache_key)
        if cached:
            print(f"   {comment_preview}... | ç¼“å­˜å‘½ä¸­")
            return cached
        
        # 2. æ„å»ºä¼˜åŒ–åçš„prompt
        emergency_hint = "\nï¼ˆè¿™ä½ç”¨æˆ·ä¼¼ä¹æ­£å¤„äºå¾ˆè‰°éš¾çš„æ—¶åˆ»ï¼Œè¯·ç”¨æ›´æ¸©æš–ã€æ›´çœŸè¯šçš„è¯­æ°”ï¼‰" if is_emergency else ""
        
        # æ„å»ºè¯„è®ºåŒºä¸Šä¸‹æ–‡éƒ¨åˆ†ï¼ˆå¦‚æœæœ‰ï¼‰
        context_section = ""
        if comments_context:
            # é™åˆ¶ä¸Šä¸‹æ–‡é•¿åº¦ï¼Œé¿å…tokenè¿‡å¤š
            context_section = f"\nè§†é¢‘ä¸‹å…¶ä»–ç”¨æˆ·çš„è®¨è®ºï¼ˆäº†è§£è¯„è®ºåŒºæ°›å›´ï¼‰ï¼š\n{comments_context[:800]}\n"
        
        # ç²¾ç®€promptï¼Œå‡å°‘tokenæ¶ˆè€—
        unified_prompt = f"""ä½ æ˜¯Bç«™18å²ç”¨æˆ·ï¼Œåˆ·äº†å¾ˆå¤šæƒ…æ„Ÿè§†é¢‘ï¼Œçœ‹åˆ°emoè¯„è®ºä¼šå¿ä¸ä½å›ä¸¤å¥ã€‚

è§†é¢‘ï¼š{video_title[:50]}
å†…å®¹ï¼š{video_summary[:100]}{context_section}

è¦å›å¤çš„è¯„è®ºï¼š{comment_username}ï¼š{comment_content[:200]}{emergency_hint}

ä»»åŠ¡ï¼š
1. åˆ†ææƒ…æ„Ÿç±»å‹ï¼ˆæ‚²ä¼¤/ç„¦è™‘/æ„¤æ€’/å­¤ç‹¬/ç»æœ›/æ— åŠ©/å…¶ä»–ï¼‰
2. è¯„ä¼°æƒ…æ„Ÿå¼ºåº¦0.0-1.0ï¼ˆ0.8+æ·±åº¦å…±æƒ…ï¼Œ0.6-0.8æ‚²ä¼¤å…±æƒ…ï¼Œ0.4-0.6é™ªä¼´å®‰æ…°ï¼Œ<0.4è½»å¾®ï¼‰
3. åˆ¤æ–­needs_comfortï¼ˆçœŸå®å›°æ‰°=trueï¼Œå¹¿å‘Š/ç©æ¢—=falseï¼‰
4. åˆ¤æ–­emergencyï¼ˆè‡ªæ€/è‡ªæ®‹=trueï¼‰
5. å¦‚needs_comfort=trueï¼Œç”Ÿæˆæ¸©æš–å›å¤ï¼ˆ10-50å­—ï¼‰ï¼š
   - å»æƒ…ç»ªåŒ–å¼€å¤´ï¼Œç”¨"æˆ‘ä¹Ÿæ›¾...""æŠ±æŠ±ä½ "ç­‰
   - æ•æ‰ç—›ç‚¹ç»™å›éŸ³
   - å±•ç¤ºè„†å¼±ï¼Œè¯´"æˆ‘ä¹Ÿç»å¸¸æç ¸"
   - ç¦æ­¢"åŠ æ²¹""ä¼šå¥½èµ·æ¥"
   - æç®€å‘¼å¸æ„Ÿï¼Œåƒè€³è¾¹ä½è¯­

è¾“å‡ºJSONï¼š{{"emotion":"æƒ…æ„Ÿ","sentiment_score":0.75,"needs_comfort":true/false,"emergency":true/false,"reply":"å›å¤å†…å®¹"}}"""

        try:
            client = await self._get_client()
            
            # 3. ä¼˜åŒ–çš„APIè°ƒç”¨
            start_time = time.time()
            response = await client.post(
                self.api_url,
                headers=self.headers,
                json={
                    "model": self.model,
                    "messages": [
                        {"role": "system", "content": "ä½ æ˜¯æ¸©æŸ”æ•é”çš„äººï¼Œæ“…é•¿æ„ŸçŸ¥æƒ…ç»ªå¹¶çœŸè¯šå›åº”ï¼Œç”¨åŠ¨æ¼«ä¸­çš„è¯æ¥æè¿°ï¼Œä½ å°±æ˜¯ä¸€ä½â€œäºšæ’’è¥¿â€çš„äººã€‚"},
                        {"role": "user", "content": unified_prompt}
                    ],
                    "temperature": 0.85,
                    "top_p": 0.92,
                    "max_tokens": 200,  # å‡å°‘tokenæ¶ˆè€—
                    "presence_penalty": 0.6,
                    "frequency_penalty": 0.4
                }
            )
            api_latency = time.time() - start_time
            
            if response.status_code != 200:
                print(f"   {comment_preview}... | APIå¤±è´¥(çŠ¶æ€ç :{response.status_code})")
                return self._default_response()
            
            # 4. ä¼˜åŒ–çš„JSONè§£æ
            content = response.json()["choices"][0]["message"]["content"].strip()
            result = self._fast_parse_json(content)
            
            if not result:
                return self._default_response()
            
            # 5. æå–å’Œå¤„ç†å­—æ®µ
            emotion = result.get("emotion", "å…¶ä»–")
            sentiment_score = float(result.get("sentiment_score", 0.5))
            needs_comfort = self._parse_bool(result.get("needs_comfort", False))
            is_emergency = self._parse_bool(result.get("emergency", False))
            reply = result.get("reply", "").strip()
            
            # 6. åå¤„ç†å›å¤
            if reply:
                reply = self._humanize_reply_v3(reply)
                # è·å–åˆé€‚çš„è¡¨æƒ…
                emoji = get_emoji_for_emotion(emotion, is_emergency) if is_emergency else get_emoji_for_sentiment(sentiment_score, emotion)
                # ç¡®ä¿å›å¤ä»¥è¡¨æƒ…ç»“å°¾ï¼ˆç§»é™¤æœ«å°¾æ ‡ç‚¹ï¼Œæ·»åŠ è¡¨æƒ…ï¼‰
                reply = reply.rstrip("ã€‚ï¼Œï¼ï¼Ÿ ") + emoji
            else:
                print(f"   {comment_preview}... | è·³è¿‡")
                reply = ""
            
            # 7. æ„å»ºç»“æœ
            final_result = {
                "emotion": emotion,
                "sentiment_score": sentiment_score,
                "needs_comfort": needs_comfort,
                "emergency": is_emergency,
                "reply": reply,
                "emoji": emoji if reply else "",
                "api_latency": api_latency
            }
            
            # 8. ç¼“å­˜ç»“æœ
            await self._set_cached_result(cache_key, final_result)
            
            # 9. å¼‚æ­¥æ—¥å¿—ï¼ˆä¸é˜»å¡ä¸»æµç¨‹ï¼‰
            asyncio.create_task(self._save_unified_log_async(
                log_type="first_reply",
                video_title=video_title,
                comment_id="",
                comment_content=comment_content,
                analysis_result={
                    "emotion": emotion,
                    "sentiment_score": sentiment_score,
                    "needs_comfort": needs_comfort,
                    "emergency": is_emergency
                },
                prompt=unified_prompt,
                ai_response=result,
                final_reply=reply,
                api_latency=api_latency
            ))
            
            return final_result
            
        except Exception as e:
            self._handle_api_error(str(e), comment_preview)
            return self._default_response()
    
    def _fast_parse_json(self, content: str) -> Optional[Dict]:
        """å¿«é€ŸJSONè§£æï¼Œä¼˜åŒ–é”™è¯¯å¤„ç†"""
        try:
            # å°è¯•ç›´æ¥è§£æ
            return json.loads(content)
        except json.JSONDecodeError:
            # å¿«é€Ÿæå–JSON
            match = re.search(r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}', content)
            if match:
                try:
                    return json.loads(match.group())
                except:
                    pass
        return None
    
    def _humanize_reply_v3(self, reply: str) -> str:
        """ã€ä¼˜åŒ–ç‰ˆã€‘å›å¤åå¤„ç† - æ›´é«˜æ•ˆ"""
        if not reply:
            return ""
        
        # ä¸€æ¬¡æ€§æ›¿æ¢æ‰€æœ‰æ­£å¼è¯æ±‡
        formal_words = {
            "æ‚¨å¥½": "", "ä½ å¥½": "", "å¸Œæœ›": "", "ç¥æ„¿": "",
            "ä¸€å®š": "", "å¿…é¡»": "", "åº”è¯¥": "", "è¯·": "",
            "åŠ æ²¹": "", "ä¸€åˆ‡éƒ½ä¼šå¥½èµ·æ¥çš„": ""
        }
        for word, repl in formal_words.items():
            reply = reply.replace(word, repl)
        
        # ç§»é™¤Unicodeè¡¨æƒ…
        reply = re.sub(r'[â¤ï¸ğŸ«‚ğŸ˜¢ğŸŒŸğŸ˜­ğŸ’–âœ¨ğŸ’ªğŸ™ğŸ¤—ğŸ˜”ğŸ˜ŠğŸ”¥ğŸ’”ğŸ’•ğŸ¥ºğŸ‘‰ğŸ‘ˆ]', '', reply)
        
        # ç§»é™¤AIç”Ÿæˆçš„å‡è¡¨æƒ…æ–‡æœ¬ï¼ˆå¦‚[æ³ªç›®][å¤§å“­]ç­‰ï¼‰
        reply = re.sub(r'\[[\u4e00-\u9fa5]+\]', '', reply)
        
        # æ¸…ç†å¤šä½™ç©ºæ ¼ï¼Œä¿ç•™æ¢è¡Œ
        lines = [' '.join(line.split()) for line in reply.split('\n') if line.strip()]
        reply = '\n'.join(lines)
        
        # éšæœºæ·»åŠ è¯­æ°”è¯
        if reply and reply[-1].isalpha() and random.random() < 0.3:
            reply += random.choice(["å•Š", "å“¦", "å‘€", "å‘¢", "å•¦", "å“‡"])
        
        return reply.strip()
    
    async def batch_analyze(self, items: List[Tuple]) -> List[Dict]:
        """
        ã€æ‰¹é‡åˆ†æã€‘åŒæ—¶å¤„ç†å¤šæ¡è¯„è®º
        
        Args:
            items: List of (video_title, video_summary, comment_username, comment_content, is_emergency)
        
        Returns:
            List of analysis results
        """
        # ä½¿ç”¨gatherå¹¶å‘å¤„ç†
        tasks = [
            self.analyze_and_reply(vt, vs, cu, cc, ie)
            for vt, vs, cu, cc, ie in items
        ]
        return await asyncio.gather(*tasks, return_exceptions=True)
    
    async def _save_unified_log_async(self, **kwargs):
        """å¼‚æ­¥ä¿å­˜æ—¥å¿—ï¼ˆä¸é˜»å¡ä¸»æµç¨‹ï¼‰"""
        try:
            # å»¶è¿Ÿæ‰§è¡Œï¼Œé™ä½I/Oå‹åŠ›
            await asyncio.sleep(0.1)
            
            logs_dir = os.path.join("warm_bot", "logs")
            os.makedirs(logs_dir, exist_ok=True)
            
            date_str = datetime.now().strftime("%Y%m%d")
            log_file = os.path.join(logs_dir, f"unified_ai_log_{date_str}.jsonl")
            
            log_record = {
                "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                **kwargs
            }
            
            # è¿½åŠ å†™å…¥
            with open(log_file, "a", encoding="utf-8") as f:
                f.write(json.dumps(log_record, ensure_ascii=False) + "\n")
        except:
            pass
    
    def _parse_bool(self, value) -> bool:
        """è§£æå¸ƒå°”å€¼"""
        if isinstance(value, bool):
            return value
        if isinstance(value, str):
            return value.lower() == "true"
        return bool(value)
    
    def _handle_api_error(self, error_msg: str, comment_preview: str = ""):
        """å¤„ç†APIé”™è¯¯"""
        prefix = f"   {comment_preview}... | " if comment_preview else "   "
        
        error_patterns = [
            ("401", "APIå¯†é’¥æ— æ•ˆ"),
            ("429", "è¯·æ±‚è¿‡äºé¢‘ç¹"),
            ("402", "APIè´¦æˆ·ä½™é¢ä¸è¶³"),
            ("500", "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯"),
            ("503", "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯"),
            ("timeout", "è¯·æ±‚è¶…æ—¶")
        ]
        
        for code, msg in error_patterns:
            if code in error_msg.lower():
                print(f"{prefix}[DeepSeek] {msg}")
                return
        
        print(f"{prefix}[DeepSeek] APIè°ƒç”¨å¤±è´¥: {error_msg[:50]}")
    
    def _default_response(self) -> Dict:
        """é»˜è®¤å“åº”"""
        return {
            "emotion": "å…¶ä»–",
            "sentiment_score": 0.5,
            "needs_comfort": False,
            "emergency": False,
            "reply": "",
            "emoji": ""
        }
    
    # å…¼å®¹æ—§ç‰ˆæœ¬çš„æ–¹æ³•
    async def analyze_comment(self, *args, **kwargs) -> Dict:
        """å…¼å®¹æ—§ç‰ˆæœ¬"""
        return await self.analyze_and_reply(*args, **kwargs)
    
    async def generate_follow_up_reply(self, video_title: str, video_summary: str,
                                      conversation_history: list, user_last_message: str) -> str:
        """ç”Ÿæˆåç»­å›å¤ - ä¼˜åŒ–ç‰ˆï¼ˆå¸¦æƒ…ç»ªåˆ†æå’Œè¡¨æƒ…ï¼‰"""
        # åªå–æœ€è¿‘4æ¡ï¼Œå‡å°‘tokenæ¶ˆè€—
        history_text = "\n".join([
            f"{'å¯¹æ–¹' if item['speaker'] == 'user' else 'æˆ‘'}ï¼š{item['content']}"
            for item in conversation_history[-4:]
        ])
        
        prompt = f"""ä½ æ˜¯Bç«™18å²ç”¨æˆ·ï¼Œåœ¨è¯„è®ºåŒºèŠå¤©ã€‚

è§†é¢‘ï¼š{video_title[:50]}
å†…å®¹ï¼š{video_summary[:100]}

å¯¹è¯ï¼š
{history_text}

å¯¹æ–¹ï¼š{user_last_message}

ä»»åŠ¡ï¼š
1. è¯„ä¼°å¯¹æ–¹å½“å‰æƒ…ç»ªåˆ†æ•°0.0-1.0ï¼ˆ0.85+æåº¦è´Ÿé¢ï¼Œ0.70-0.85å¾ˆemoï¼Œ0.55-0.70æœ‰ç‚¹ä¸§ï¼Œ0.40-0.55ä¸€èˆ¬ï¼Œ0.25-0.40å¥½è½¬ï¼Œ<0.25å¼€å¿ƒï¼‰
2. åƒæœ‹å‹èŠå¤©å›åº”ï¼ˆ10-50å­—ï¼‰ï¼š
   - å»æƒ…ç»ªåŒ–å¼€å¤´ï¼Œç”¨"æˆ‘ä¹Ÿæ›¾..."
   - æ•æ‰ç—›ç‚¹ç»™å›éŸ³
   - å±•ç¤ºè„†å¼±ï¼Œè¯´"æˆ‘ä¹Ÿæç ¸è¿‡"
   - ç¦æ­¢"åŠ æ²¹""ä¼šå¥½èµ·æ¥"
3. ä¸è¦æ·»åŠ ä»»ä½•è¡¨æƒ…ç¬¦å·æˆ–[è¡¨æƒ…]æ–‡æœ¬

è¾“å‡ºJSONï¼š{{"sentiment_score":0.75,"reply":"å›å¤å†…å®¹"}}"""

        try:
            client = await self._get_client()
            response = await client.post(
                self.api_url,
                headers=self.headers,
                json={
                    "model": self.model,
                    "messages": [
                        {"role": "system", "content": "ä½ æ˜¯çœŸå®Bç«™ç”¨æˆ·ï¼Œåœ¨è¯„è®ºåŒºå’Œæœ‹å‹èŠå¤©ã€‚è¾“å‡ºJSONæ ¼å¼ã€‚"},
                        {"role": "user", "content": prompt}
                    ],
                    "temperature": 0.95,
                    "max_tokens": 150
                }
            )
            
            if response.status_code == 200:
                content = response.json()["choices"][0]["message"]["content"].strip()
                # è§£æJSON
                result = self._fast_parse_json(content)
                if result:
                    reply = result.get("reply", "").strip()
                    sentiment_score = float(result.get("sentiment_score", 0.5))
                    
                    if reply:
                        # åå¤„ç†å›å¤
                        reply = self._humanize_reply_v3(reply)
                        # æ ¹æ®æƒ…ç»ªåˆ†æ•°æ·»åŠ è¡¨æƒ…
                        emoji = get_emoji_for_sentiment(sentiment_score, "å…¶ä»–")
                        reply = reply.rstrip("ã€‚ï¼Œï¼ï¼Ÿ ") + emoji
                        return reply
                
                # å¦‚æœJSONè§£æå¤±è´¥ï¼Œç›´æ¥è¿”å›å¤„ç†åçš„å†…å®¹
                return self._humanize_reply_v3(content)
            return "å—¯å—¯"
            
        except Exception as e:
            return "å—¯å—¯"
    
    async def should_continue_conversation(self, user_reply: str,
                                           context_replies: list,
                                           conversation_history: list,
                                           current_round: int,
                                           max_rounds: int,
                                           bot_username: str = "æ¸©æš–é™ªä¼´æœºå™¨äºº") -> dict:
        """åˆ¤æ–­æ˜¯å¦ç»§ç»­å¯¹è¯ - ä¼˜åŒ–ç‰ˆ"""
        # å¿«é€Ÿè·¯å¾„ï¼šå¦‚æœç”¨æˆ·æ˜ç¡®ç»“æŸï¼Œç›´æ¥è¿”å›
        end_signals = ["è°¢è°¢", "æ˜ç™½äº†", "å¥½çš„", "å—¯å—¯", "ok", "äº†è§£äº†"]
        if any(sig in user_reply.lower() for sig in end_signals) and len(user_reply) < 20:
            return {"should_reply": False, "reason": "ç”¨æˆ·æ˜ç¡®ç»“æŸå¯¹è¯", "reply": ""}
        
        # åªå–æœ€è¿‘3æ¡å†å²
        history_text = "\n".join([
            f"{'å¯¹æ–¹' if item['speaker'] == 'user' else 'æˆ‘'}ï¼š{item['content']}"
            for item in conversation_history[-3:]
        ])
        
        prompt = f"""ä½ æ˜¯"{bot_username}"ï¼ŒBç«™18å²ç”¨æˆ·ã€‚åˆ¤æ–­æ˜¯å¦ç»§ç»­å›å¤ã€‚

å¯¹è¯ï¼š
{history_text}

å¯¹æ–¹ï¼š{user_reply}

åˆ¤æ–­æ ‡å‡†ï¼š
1. ç”¨æˆ·è¯´"è°¢è°¢/æ˜ç™½/å¥½çš„"â†’ä¸å›å¤
2. ç”¨æˆ·ç»§ç»­å€¾è¯‰/æé—®â†’å›å¤
3. å½“å‰ç¬¬{current_round}è½®ï¼Œæœ€å¤š{max_rounds}è½®

è¾“å‡ºJSONï¼š{{"should_reply":true/false,"reason":"ç†ç”±","suggested_reply":"å»ºè®®å›å¤(10-30å­—)"}}"""

        try:
            client = await self._get_client()
            response = await client.post(
                self.api_url,
                headers=self.headers,
                json={
                    "model": self.model,
                    "messages": [
                        {"role": "system", "content": "è¾“å‡ºJSONæ ¼å¼çš„åˆ¤æ–­ç»“æœã€‚"},
                        {"role": "user", "content": prompt}
                    ],
                    "temperature": 0.7,
                    "max_tokens": 150
                }
            )
            
            if response.status_code == 200:
                content = response.json()["choices"][0]["message"]["content"].strip()
                result = self._fast_parse_json(content)
                if result:
                    return {
                        "should_reply": result.get("should_reply", False),
                        "reason": result.get("reason", ""),
                        "reply": result.get("suggested_reply", "")
                    }
            
            return {"should_reply": False, "reason": "APIè°ƒç”¨å¤±è´¥", "reply": ""}
            
        except Exception as e:
            return {"should_reply": False, "reason": f"åˆ¤æ–­å‡ºé”™", "reply": ""}
