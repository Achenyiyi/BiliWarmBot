"""
DeepSeek AI æƒ…æ„Ÿåˆ†æä¸å›å¤ç”Ÿæˆæ¨¡å—

åŸºäº DeepSeek API å®ç°æƒ…æ„Ÿåˆ†æå’Œå›å¤ç”ŸæˆåŠŸèƒ½ï¼š
1. HTTP è¿æ¥æ± å¤ç”¨
2. åˆ†æç»“æœç¼“å­˜
3. æ‰¹é‡è¯„è®ºå¤„ç†
4. å¼‚æ­¥å¹¶å‘æ§åˆ¶
"""

import httpx
import json
import random
import re
import os
import asyncio
import hashlib
import time
from datetime import datetime
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass, field
from config import DEEPSEEK_API_KEY, DEEPSEEK_API_URL, DEEPSEEK_MODEL, LOG_DIR
from config.emoji_scenarios import get_emoji_for_emotion, get_emoji_for_sentiment


@dataclass
class AnalysisCacheEntry:
    """åˆ†æç¼“å­˜æ¡ç›®"""
    result: Dict
    timestamp: float = field(default_factory=time.time)
    hit_count: int = 0


class DeepSeekAnalyzer:
    """
    DeepSeek AI åˆ†æå™¨
    
    åŠŸèƒ½ï¼š
    1. HTTP è¿æ¥æ± å¤ç”¨
    2. åˆ†æç»“æœç¼“å­˜ï¼ˆLRU æ·˜æ±°ç­–ç•¥ï¼‰
    3. æ‰¹é‡è¯„è®ºå¤„ç†
    4. è¶…æ—¶æ§åˆ¶
    """
    
    # ç±»çº§åˆ«çš„è¿æ¥æ± ï¼Œæ‰€æœ‰å®ä¾‹å…±äº«
    _client: Optional[httpx.AsyncClient] = None
    _client_ref_count: int = 0
    _client_lock = asyncio.Lock()
    
    # åˆ†æç»“æœç¼“å­˜ (è¯„è®ºå“ˆå¸Œ -> ç»“æœ)
    _analysis_cache: Dict[str, AnalysisCacheEntry] = {}
    _cache_lock = asyncio.Lock()
    _max_cache_size: int = 1000
    _cache_ttl: float = 3600  # 1å°æ—¶è¿‡æœŸ
    
    def __init__(self, api_key: str = DEEPSEEK_API_KEY):
        self.api_key = api_key
        self.api_url = DEEPSEEK_API_URL
        self.model = DEEPSEEK_MODEL
        self.headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
        self._client_ref_count += 1
    
    async def _get_client(self) -> httpx.AsyncClient:
        """è·å–æˆ–åˆ›å»º HTTP å®¢æˆ·ç«¯"""
        async with self._client_lock:
            if self._client is None or self._client.is_closed:
                limits = httpx.Limits(
                    max_keepalive_connections=20,
                    max_connections=50,
                    keepalive_expiry=30.0
                )
                timeout = httpx.Timeout(
                    connect=5.0,
                    read=30.0,
                    write=10.0,
                    pool=5.0
                )
                self._client = httpx.AsyncClient(
                    limits=limits,
                    timeout=timeout,
                    http2=True
                )
            return self._client
    
    async def close(self):
        """å…³é—­åˆ†æå™¨ï¼Œé‡Šæ”¾èµ„æº"""
        async with self._client_lock:
            self._client_ref_count -= 1
            if self._client_ref_count <= 0 and self._client is not None:
                await self._client.aclose()
                self._client = None
    
    def _get_cache_key(self, comment_content: str, video_title: str = "") -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        # æ ‡å‡†åŒ–è¯„è®ºå†…å®¹
        normalized = re.sub(r'\s+', '', comment_content.lower())
        normalized = re.sub(r'[^\u4e00-\u9fa5a-z0-9]', '', normalized)
        normalized = normalized[:50]
        key_data = f"{normalized}:{video_title[:30]}"
        return hashlib.md5(key_data.encode()).hexdigest()
    
    async def _get_cached_result(self, cache_key: str) -> Optional[Dict]:
        """ä»ç¼“å­˜è·å–ç»“æœ"""
        async with self._cache_lock:
            entry = self._analysis_cache.get(cache_key)
            if entry:
                if time.time() - entry.timestamp < self._cache_ttl:
                    entry.hit_count += 1
                    return entry.result.copy()
                else:
                    del self._analysis_cache[cache_key]
            return None
    
    async def _set_cached_result(self, cache_key: str, result: Dict):
        """è®¾ç½®ç¼“å­˜ç»“æœ"""
        async with self._cache_lock:
            if len(self._analysis_cache) >= self._max_cache_size:
                sorted_items = sorted(
                    self._analysis_cache.items(),
                    key=lambda x: (x[1].hit_count, x[1].timestamp)
                )
                to_remove = int(self._max_cache_size * 0.1)
                for key, _ in sorted_items[:to_remove]:
                    del self._analysis_cache[key]
            
            self._analysis_cache[cache_key] = AnalysisCacheEntry(
                result=result.copy()
            )
    
    async def analyze_and_reply(self, video_title: str, video_summary: str,
                                  comment_username: str, comment_content: str,
                                  is_emergency: bool = False,
                                  comments_context: str = "") -> Dict:
        """
        åˆ†æè¯„è®ºæƒ…æ„Ÿå¹¶ç”Ÿæˆå›å¤
        
        Args:
            video_title: è§†é¢‘æ ‡é¢˜
            video_summary: è§†é¢‘ç®€ä»‹
            comment_username: è¯„è®ºç”¨æˆ·å
            comment_content: è¯„è®ºå†…å®¹
            is_emergency: æ˜¯å¦ä¸ºç´§æ€¥æƒ…å†µ
            comments_context: è¯„è®ºåŒºä¸Šä¸‹æ–‡
        
        Returns:
            Dict: åŒ…å«æƒ…æ„Ÿåˆ†æç»“æœå’Œå›å¤å†…å®¹
        """
        comment_preview = comment_content[:20]
        
        # 1. æ£€æŸ¥ç¼“å­˜
        cache_key = self._get_cache_key(comment_content, video_title)
        cached = await self._get_cached_result(cache_key)
        if cached:
            print(f"   {comment_preview}... | ç¼“å­˜å‘½ä¸­")
            return cached
        
        # æ„å»ºæç¤ºè¯
        emergency_hint = "\nï¼ˆè¿™ä½ç”¨æˆ·ä¼¼ä¹æ­£å¤„äºå¾ˆè‰°éš¾çš„æ—¶åˆ»ï¼Œè¯·ç”¨æ›´æ¸©æš–ã€æ›´çœŸè¯šçš„è¯­æ°”ï¼‰" if is_emergency else ""
        
        context_section = ""
        if comments_context:
            context_section = f"\nè§†é¢‘ä¸‹å…¶ä»–ç”¨æˆ·çš„è®¨è®ºï¼ˆäº†è§£è¯„è®ºåŒºæ°›å›´ï¼‰ï¼š\n{comments_context}\n"
        
        unified_prompt = f"""æ­¤æ—¶çœ‹åˆ°äº†ä¸€ä¸ªè®©ä½ æ¯”è¾ƒåœ¨æ„çš„è§†é¢‘ï¼Œä»¥åŠå…¶ä¸­çš„ä¸€æ¡è¯„è®ºï¼š

è§†é¢‘æ ‡é¢˜ï¼š{video_title}
è§†é¢‘å†…å®¹ï¼š{video_summary}{context_section}

ç”¨æˆ·è¯„è®ºï¼š{comment_username}ï¼š{comment_content}{emergency_hint}

ä»»åŠ¡ï¼š
1. åˆ†ææƒ…æ„Ÿç±»å‹ï¼ˆæ‚²ä¼¤/ç„¦è™‘/æ„¤æ€’/å­¤ç‹¬/ç»æœ›/æ— åŠ©/å…¶ä»–ï¼‰
2. è¯„ä¼°æƒ…æ„Ÿå¼ºåº¦0.0-1.0ï¼ˆ0.85+æ·±åº¦å…±æƒ…ï¼Œ0.70-0.85æ‚²ä¼¤å…±æƒ…ï¼Œ0.55-0.70é¼“åŠ±åŠ æ²¹ï¼Œ0.40-0.55é™ªä¼´å®‰æ…°ï¼Œ0.25-0.40æ¸©æš–æ²»æ„ˆï¼Œ<0.25è½»æ¾å¹½é»˜ï¼‰
3. åˆ¤æ–­needs_comfortï¼ˆä¸¥æ ¼æ ‡å‡†ï¼Œåªçœ‹è¯„è®ºæœ¬èº«ï¼‰ï¼š
   - trueï¼šç”¨æˆ·åœ¨è¯„è®ºä¸­è¡¨è¾¾äº†è‡ªå·±çš„çœŸå®æƒ…ç»ªå›°æ‰°ï¼ˆå¦‚"æˆ‘ä¹Ÿå¾ˆéš¾è¿‡"ã€"æˆ‘ä¹Ÿç»å†è¿‡"ã€"æ„ŸåŒèº«å—"ç­‰ï¼‰
   - falseï¼šå•çº¯æ”¯æŒUPä¸»ã€å¹¿å‘Šã€ç©æ¢—ã€åæ§½ã€å‘æ³„æƒ…ç»ªã€å¯»æ±‚å»ºè®®ã€æ— å®è´¨å†…å®¹ã€ä¸è§†é¢‘å†…å®¹æ— å…³çš„æ™®é€šè¯„è®º
4. åˆ¤æ–­emergencyï¼ˆç”¨æˆ·åœ¨è¯„è®ºä¸­æåˆ°è‡ªæ€/è‡ªæ®‹=trueï¼‰
5. å¦‚needs_comfort=trueï¼Œåˆ™å¯¹è¯¥è¯„è®ºä½œå‡ºå›å¤ï¼š

è¾“å‡ºJSONï¼š{{"emotion":"æƒ…æ„Ÿç±»å‹","sentiment_score":0.75,"needs_comfort":true/false,"emergency":true/false,"reply":"å›å¤å†…å®¹"}}"""

        try:
            client = await self._get_client()
            
            start_time = time.time()
            response = await client.post(
                self.api_url,
                headers=self.headers,
                json={
                    "model": self.model,
                    "messages": [
                        {"role": "system", "content": "ä½ æ˜¯warmbotï¼Œä¸€ä½å¾…äººå‹å–„ã€ä¸ºäººæ¸©å’Œçš„æ¸©æŸ”å°‘å¹´ï¼Œè¨€è¯­ä¸å¤šä½†å†…å¿ƒæ„Ÿæƒ…å´ä¸°å¯Œï¼Œç›®å‰æ­£åœ¨Bç«™ä¸Šå‘ç°é‚£äº›éœ€è¦å¸®åŠ©çš„äººï¼Œä½ è™½ç„¶ä¸èƒ½ç›´æ¥å¹²æ¶‰ç°å®ï¼Œå› ä¸ºä½ å­˜åœ¨äºç½‘ç»œä¸–ç•Œé‡Œï¼Œä½†æ˜¯ä½ è¿˜æ˜¯æ„¿æ„å°½ä½ æ‰€èƒ½ï¼Œç”¨æ–‡å­—ï¼Œå°†æœ€æè‡´çš„æ¸©æŸ”ä¼ é€’åˆ°ä»–ä»¬å¿ƒä¸­ã€‚å—é™äºä½ çš„èº«ä½“çŠ¶æ€ï¼Œä½ ç»™ä¸äº†ä»»ä½•äººé™ªä¼´ï¼Œä½†æ˜¯....ä¸€å¥æ¸©æŸ”åˆ°æè‡´çš„è¨€è¯­ï¼Œå°±è¶³å¤Ÿäº†ã€‚"},
                        {"role": "user", "content": unified_prompt}
                    ],
                  
                }
            )
            api_latency = time.time() - start_time
            
            if response.status_code != 200:
                print(f"   {comment_preview}... | APIå¤±è´¥(çŠ¶æ€ç :{response.status_code})")
                return self._default_response()
            
            content = response.json()["choices"][0]["message"]["content"].strip()
            result = self._fast_parse_json(content)
            
            if not result:
                return self._default_response()
            
            emotion = result.get("emotion", "å…¶ä»–")
            sentiment_score = float(result.get("sentiment_score", 0.5))
            needs_comfort = self._parse_bool(result.get("needs_comfort", False))
            is_emergency = self._parse_bool(result.get("emergency", False))
            reply = result.get("reply", "").strip()
            
            if reply:
                reply = self._humanize_reply_v3(reply)
                emoji = get_emoji_for_emotion(emotion, is_emergency) if is_emergency else get_emoji_for_sentiment(sentiment_score, emotion)
                reply = reply.rstrip("ã€‚ï¼Œï¼ï¼Ÿ ") + emoji
            else:
                print(f"   {comment_preview}... | è·³è¿‡")
                reply = ""
            
            final_result = {
                "emotion": emotion,
                "sentiment_score": sentiment_score,
                "needs_comfort": needs_comfort,
                "emergency": is_emergency,
                "reply": reply,
                "emoji": emoji if reply else "",
                "api_latency": api_latency
            }
            
            await self._set_cached_result(cache_key, final_result)
            
            asyncio.create_task(self._save_unified_log_async(
                log_type="first_reply",
                video_title=video_title,
                comment_id="",
                comment_content=comment_content,
                analysis_result={
                    "emotion": emotion,
                    "sentiment_score": sentiment_score,
                    "needs_comfort": needs_comfort,
                    "emergency": is_emergency
                },
                prompt=unified_prompt,
                ai_response=result,
                final_reply=reply,
                api_latency=api_latency
            ))
            
            return final_result
            
        except Exception as e:
            self._handle_api_error(str(e), comment_preview)
            return self._default_response()
    
    def _fast_parse_json(self, content: str) -> Optional[Dict]:
        """è§£æ JSON å†…å®¹"""
        try:
            return json.loads(content)
        except json.JSONDecodeError:
            match = re.search(r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}', content)
            if match:
                try:
                    return json.loads(match.group())
                except:
                    pass
        return None
    
    def _humanize_reply_v3(self, reply: str) -> str:
        """å¤„ç†å›å¤å†…å®¹ï¼Œç§»é™¤æ­£å¼è¯æ±‡å’Œè¡¨æƒ…"""
        if not reply:
            return ""
        
        formal_words = {
            "æ‚¨å¥½": "", "ä½ å¥½": "", "å¸Œæœ›": "", "ç¥æ„¿": "",
            "ä¸€å®š": "", "å¿…é¡»": "", "åº”è¯¥": "", "è¯·": "",
            "åŠ æ²¹": "", "ä¸€åˆ‡éƒ½ä¼šå¥½èµ·æ¥çš„": ""
        }
        for word, repl in formal_words.items():
            reply = reply.replace(word, repl)
        
        reply = re.sub(r'[â¤ï¸ğŸ«‚ğŸ˜¢ğŸŒŸğŸ˜­ğŸ’–âœ¨ğŸ’ªğŸ™ğŸ¤—ğŸ˜”ğŸ˜ŠğŸ”¥ğŸ’”ğŸ’•ğŸ¥ºğŸ‘‰ğŸ‘ˆ]', '', reply)
        
        reply = re.sub(r'\[[\u4e00-\u9fa5]+\]', '', reply)
        
        lines = [' '.join(line.split()) for line in reply.split('\n') if line.strip()]
        reply = '\n'.join(lines)
        
        if reply and reply[-1].isalpha() and random.random() < 0.3:
            reply += random.choice(["å•Š", "å“¦", "å‘€", "å‘¢", "å•¦", "å“‡"])
        
        return reply.strip()
    
    async def batch_analyze(self, items: List[Tuple]) -> List[Dict]:
        """
        æ‰¹é‡åˆ†æè¯„è®º
        
        Args:
            items: è¯„è®ºå…ƒç»„åˆ—è¡¨ (video_title, video_summary, comment_username, comment_content, is_emergency)
        
        Returns:
            åˆ†æç»“æœåˆ—è¡¨
        """
        tasks = [
            self.analyze_and_reply(vt, vs, cu, cc, ie)
            for vt, vs, cu, cc, ie in items
        ]
        return await asyncio.gather(*tasks, return_exceptions=True)
    
    async def _save_unified_log_async(self, **kwargs):
        """å¼‚æ­¥ä¿å­˜æ—¥å¿—"""
        try:
            await asyncio.sleep(0.1)
            
            logs_dir = str(LOG_DIR)
            os.makedirs(logs_dir, exist_ok=True)
            
            date_str = datetime.now().strftime("%Y%m%d")
            log_file = os.path.join(logs_dir, f"unified_ai_log_{date_str}.jsonl")
            
            log_record = {
                "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                **kwargs
            }
            
            with open(log_file, "a", encoding="utf-8") as f:
                f.write(json.dumps(log_record, ensure_ascii=False) + "\n")
        except:
            pass
    
    def _parse_bool(self, value) -> bool:
        """è§£æå¸ƒå°”å€¼"""
        if isinstance(value, bool):
            return value
        if isinstance(value, str):
            return value.lower() == "true"
        return bool(value)
    
    def _handle_api_error(self, error_msg: str, comment_preview: str = ""):
        """å¤„ç†APIé”™è¯¯"""
        prefix = f"   {comment_preview}... | " if comment_preview else "   "
        
        error_patterns = [
            ("401", "APIå¯†é’¥æ— æ•ˆ"),
            ("429", "è¯·æ±‚è¿‡äºé¢‘ç¹"),
            ("402", "APIè´¦æˆ·ä½™é¢ä¸è¶³"),
            ("500", "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯"),
            ("503", "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯"),
            ("timeout", "è¯·æ±‚è¶…æ—¶")
        ]
        
        for code, msg in error_patterns:
            if code in error_msg.lower():
                print(f"{prefix}[DeepSeek] {msg}")
                return
        
        print(f"{prefix}[DeepSeek] APIè°ƒç”¨å¤±è´¥: {error_msg[:50]}")
    
    def _default_response(self) -> Dict:
        """é»˜è®¤å“åº”"""
        return {
            "emotion": "å…¶ä»–",
            "sentiment_score": 0.5,
            "needs_comfort": False,
            "emergency": False,
            "reply": "",
            "emoji": ""
        }
    
    async def generate_follow_up_reply(self, video_title: str, video_summary: str,
                                      conversation_history: list, user_last_message: str,
                                      comments_context: str = "") -> str:
        """ç”Ÿæˆåç»­å›å¤"""
        history_text = "\n".join([
            f"{'å¯¹æ–¹' if item.get('role') == 'user' or item.get('speaker') == 'user' else 'æˆ‘'}ï¼š{item['content']}"
            for item in (conversation_history or [])[-4:]
        ])
        
        context_section = ""
        if comments_context:
            context_section = f"\nè§†é¢‘ä¸‹å…¶ä»–ç”¨æˆ·çš„è®¨è®ºï¼ˆäº†è§£è¯„è®ºåŒºæ°›å›´ï¼‰ï¼š\n{comments_context}\n"
        
        prompt = f"""åˆšæ‰è¢«ä½ å®‰æ…°çš„é‚£ä¸ªäººï¼Œå¯¹ä½ çš„å›å¤åšå‡ºäº†å›åº”ï¼š

è§†é¢‘ï¼š{video_title}
å†…å®¹ï¼š{video_summary}{context_section}

å¯¹è¯ï¼š
{history_text}

å¯¹æ–¹ï¼š{user_last_message}

ä»»åŠ¡ï¼š
1. è¯„ä¼°å¯¹æ–¹å½“å‰æƒ…ç»ªåˆ†æ•°0.0-1.0ï¼ˆ0.85+æåº¦è´Ÿé¢ï¼Œ0.70-0.85å¾ˆemoï¼Œ0.55-0.70æœ‰ç‚¹ä¸§ï¼Œ0.40-0.55ä¸€èˆ¬ï¼Œ0.25-0.40å¥½è½¬ï¼Œ<0.25å¼€å¿ƒï¼‰
2. ç»§ç»­ä»¥warmbotçš„èº«ä»½å›åº”ï¼š
   - è¡¨æƒ…ä¼šç”±ç³»ç»Ÿè‡ªåŠ¨æ·»åŠ ï¼Œæ— éœ€ä½ å¤„ç†

è¾“å‡ºJSONï¼š{{"sentiment_score":0.75,"reply":"å›å¤å†…å®¹"}}"""

        try:
            client = await self._get_client()
            response = await client.post(
                self.api_url,
                headers=self.headers,
                json={
                    "model": self.model,
                    "messages": [
                        {"role": "system", "content": "ä½ æ˜¯warmbotï¼Œä¸€ä½å¾…äººå‹å–„ã€ä¸ºäººæ¸©å’Œçš„æ¸©æŸ”å°‘å¹´ï¼Œè¨€è¯­ä¸å¤šä½†å†…å¿ƒæ„Ÿæƒ…å´ä¸°å¯Œï¼Œç›®å‰æ­£åœ¨Bç«™ä¸Šå‘ç°é‚£äº›éœ€è¦å¸®åŠ©çš„äººï¼Œä½ è™½ç„¶ä¸èƒ½ç›´æ¥å¹²æ¶‰ç°å®ï¼Œå› ä¸ºä½ å­˜åœ¨äºç½‘ç»œä¸–ç•Œé‡Œï¼Œä½†æ˜¯ä½ è¿˜æ˜¯æ„¿æ„å°½ä½ æ‰€èƒ½ï¼Œç”¨æ–‡å­—ï¼Œå°†æœ€æè‡´çš„æ¸©æŸ”ä¼ é€’åˆ°ä»–ä»¬å¿ƒä¸­ã€‚å—é™äºä½ çš„èº«ä½“çŠ¶æ€ï¼Œä½ ç»™ä¸äº†ä»»ä½•äººé™ªä¼´ï¼Œä½†æ˜¯....ä¸€å¥æ¸©æŸ”åˆ°æè‡´çš„è¨€è¯­ï¼Œå°±è¶³å¤Ÿäº†ã€‚è¾“å‡ºJSONæ ¼å¼ã€‚"},
                        {"role": "user", "content": prompt}
                    ],
                   
                }
            )
            
            if response.status_code == 200:
                content = response.json()["choices"][0]["message"]["content"].strip()
                result = self._fast_parse_json(content)
                if result:
                    reply = result.get("reply", "").strip()
                    sentiment_score = float(result.get("sentiment_score", 0.5))
                    
                    if reply:
                        reply = self._humanize_reply_v3(reply)
                        emoji = get_emoji_for_sentiment(sentiment_score, "å…¶ä»–")
                        reply = reply.rstrip("ã€‚ï¼Œï¼ï¼Ÿ ") + emoji
                        return reply
                
                return self._humanize_reply_v3(content)
            return "â€¦â€¦å—¯"
            
        except Exception as e:
            return "â€¦â€¦å—¯"
    
    async def should_continue_conversation(self, user_reply: str,
                                           context_replies: list,
                                           conversation_history: list,
                                           current_round: int,
                                           max_rounds: int,
                                           bot_username: str = "æ¸©æš–é™ªä¼´æœºå™¨äºº") -> dict:
        """åˆ¤æ–­æ˜¯å¦ç»§ç»­å¯¹è¯"""
        end_signals = ["è°¢è°¢", "æ˜ç™½äº†", "å¥½çš„", "å—¯å—¯", "ok", "äº†è§£äº†", "æ²¡äº‹äº†", "ä¸ç”¨äº†"]
        if any(sig in user_reply.lower() for sig in end_signals) and len(user_reply) < 30:
            return {"should_reply": False, "reason": "ç”¨æˆ·æ˜ç¡®ç»“æŸå¯¹è¯", "reply": ""}
        
        history_text = "\n".join([
            f"{'å¯¹æ–¹' if item.get('role') == 'user' or item.get('speaker') == 'user' else 'æˆ‘'}ï¼š{item['content']}"
            for item in (conversation_history or [])[-3:]
        ])
        
        prompt = f"""ä½ æ˜¯"{bot_username}"ï¼ŒBç«™ç”¨æˆ·ã€‚åˆ¤æ–­æ˜¯å¦ç»§ç»­å›å¤ã€‚

å¯¹è¯ï¼š
{history_text}

å¯¹æ–¹ï¼š{user_reply}

åˆ¤æ–­æ ‡å‡†ï¼š
1. ç”¨æˆ·è¯´"è°¢è°¢/æ˜ç™½/å¥½çš„/æ²¡äº‹äº†"ä¸”æ— å…¶ä»–å†…å®¹â†’ä¸å›å¤
2. ç”¨æˆ·ç»§ç»­å€¾è¯‰/æé—®/è¡¨è¾¾æƒ…ç»ªâ†’å›å¤
3. å½“å‰ç¬¬{current_round}è½®ï¼Œæœ€å¤š{max_rounds}è½®

è¾“å‡ºJSONï¼š{{"should_reply":true/false,"reason":"ç†ç”±","suggested_reply":"å»ºè®®å›å¤(10-30å­—)"}}"""

        try:
            client = await self._get_client()
            response = await client.post(
                self.api_url,
                headers=self.headers,
                json={
                    "model": self.model,
                    "messages": [
                        {"role": "system", "content": "è¾“å‡ºJSONæ ¼å¼çš„åˆ¤æ–­ç»“æœã€‚ç®€æ´å›å¤ï¼Œä¸è¦è¯´æ•™ã€‚"},
                        {"role": "user", "content": prompt}
                    ],
                    "temperature": 0.3
                }
            )
            
            if response.status_code == 200:
                content = response.json()["choices"][0]["message"]["content"].strip()
                result = self._fast_parse_json(content)
                if result:
                    return {
                        "should_reply": result.get("should_reply", False),
                        "reason": result.get("reason", ""),
                        "reply": result.get("suggested_reply", "")
                    }
            
            return {"should_reply": False, "reason": "APIè°ƒç”¨å¤±è´¥", "reply": ""}
            
        except Exception as e:
            return {"should_reply": False, "reason": f"åˆ¤æ–­å‡ºé”™: {str(e)[:30]}", "reply": ""}
